{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('Glass_Quality_Participants_Data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of columns = 16  Train\n",
    "# Number of rows = 1358   Train\n",
    "\n",
    "# Number of columns = 15  Test\n",
    "# Number of rows = 583   Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns\n",
    "# Index(['grade_A_Component_1', 'grade_A_Component_2', 'max_luminosity',\n",
    "#        'thickness', 'xmin', 'xmax', 'ymin', 'ymax', 'pixel_area', 'log_area',\n",
    "#        'x_component_1', 'x_component_2', 'x_component_3', 'x_component_4',\n",
    "#        'x_component_5', 'class'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trainData.iloc[:,:-1]\n",
    "labels = trainData.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.values.reshape(-1,1)\n",
    "# labels = np.array([i[0]-1 for i in labels]).reshape(-1,1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohencoder(labels):\n",
    "    return np.array([[0.1,0.9] if i[0] == 2 else [0.9,0.1] for i in labels])\n",
    "\n",
    "ohencoded_labels = ohencoder(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohencoded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and grade_A are categorical variables\n",
    "# No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features.hist(column=[\"xmax\", \"xmin\",\"ymin\",\"ymax\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.hist(column=[\"max_luminosity\",\"pixel_area\",\"log_area\"])#,,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_area and log_area\n",
    "# xmin and xmax\n",
    "# ymin and ymax\n",
    "# The above pairs have a very high degree of positive correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['pixel_area', 'xmax','ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = features.loc[:,['max_luminosity','thickness','xmin','ymin','log_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(tfeatures)\n",
    "tfeatures = scaler.transform(tfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = pd.DataFrame(tfeatures,columns=['max_luminosity','thickness','xmin','ymin','log_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['max_luminosity','thickness','xmin','ymin','log_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = pd.concat([features,tfeatures],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = normalized_features.copy()\n",
    "cat_features = f.loc[:,['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5']]\n",
    "\n",
    "\n",
    "cat_features['newf'] = cat_features.apply(lambda x: str(int(x[0]))+str(int(x[1]))+str(int(x[2]))+str(int(x[3]))+str(int(x[4]))+str(int(x[5]))+str(int(x[6])), axis=1)\n",
    "\n",
    "cat_features = cat_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "\n",
    "cat_features = cat_features.astype('string')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "cat_features['newf'] = pd.DataFrame(labelencoder.fit_transform(cat_features.iloc[:,0]))\n",
    "\n",
    "from numpy import unique\n",
    "n_labels = len(unique(cat_features['newf']))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = normalized_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features = pd.concat([normalized_features,cat_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_newf = np.unique(norm_cat_features['newf'])\n",
    "unique_newf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout\n",
    "from keras.layers.embeddings import Embedding \n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "inputs = []\n",
    "embeddings = []\n",
    "newf_cat = Input(shape=(1,))\n",
    "\n",
    "embedding = Embedding(11, 300, input_length=1)(newf_cat)\n",
    "embedding = Reshape(target_shape=(300,))(embedding)\n",
    "inputs.append(newf_cat)\n",
    "embeddings.append(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_luminosity', 'thickness', 'xmin', 'ymin', 'log_area']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "othercols = [c for c in norm_cat_features.columns if not(c == 'newf')]\n",
    "othercols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_numeric = Input(shape=(5,))\n",
    "embedding_numeric = BatchNormalization()(Dense(30)(input_numeric)) \n",
    "inputs.append(input_numeric)\n",
    "embeddings.append(embedding_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Concatenate()(embeddings)\n",
    "x = Dense(15, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics =[tf.keras.metrics.CategoricalAccuracy()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    EarlyStopping(patience=3),\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features = norm_cat_features\n",
    "np_labels = ohencoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np_features, np_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_list = []\n",
    "test_input_list = []\n",
    "\n",
    "train_input_list.append(X_train['newf'].values)\n",
    "train_input_list.append(X_train[othercols].values)\n",
    "\n",
    "test_input_list.append(X_test['newf'].values)\n",
    "test_input_list.append(X_test[othercols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1086 samples, validate on 272 samples\n",
      "Epoch 1/4000\n",
      "1086/1086 [==============================] - 1s 501us/step - loss: 0.6492 - categorical_accuracy: 0.6508 - val_loss: 0.6531 - val_categorical_accuracy: 0.7050\n",
      "Epoch 2/4000\n",
      "1086/1086 [==============================] - 0s 47us/step - loss: 0.5842 - categorical_accuracy: 0.7231 - val_loss: 0.6194 - val_categorical_accuracy: 0.7347\n",
      "Epoch 3/4000\n",
      "1086/1086 [==============================] - 0s 48us/step - loss: 0.5491 - categorical_accuracy: 0.7454 - val_loss: 0.5958 - val_categorical_accuracy: 0.7504\n",
      "Epoch 4/4000\n",
      "1086/1086 [==============================] - 0s 44us/step - loss: 0.5366 - categorical_accuracy: 0.7580 - val_loss: 0.5779 - val_categorical_accuracy: 0.7633\n",
      "Epoch 5/4000\n",
      "1086/1086 [==============================] - 0s 43us/step - loss: 0.5172 - categorical_accuracy: 0.7688 - val_loss: 0.5590 - val_categorical_accuracy: 0.7727\n",
      "Epoch 6/4000\n",
      "1086/1086 [==============================] - 0s 38us/step - loss: 0.5111 - categorical_accuracy: 0.7757 - val_loss: 0.5399 - val_categorical_accuracy: 0.7788\n",
      "Epoch 7/4000\n",
      "1086/1086 [==============================] - 0s 40us/step - loss: 0.5048 - categorical_accuracy: 0.7824 - val_loss: 0.5291 - val_categorical_accuracy: 0.7845\n",
      "Epoch 8/4000\n",
      "1086/1086 [==============================] - 0s 38us/step - loss: 0.4994 - categorical_accuracy: 0.7875 - val_loss: 0.5246 - val_categorical_accuracy: 0.7897\n",
      "Epoch 9/4000\n",
      "1086/1086 [==============================] - 0s 39us/step - loss: 0.4901 - categorical_accuracy: 0.7917 - val_loss: 0.5221 - val_categorical_accuracy: 0.7935\n",
      "Epoch 10/4000\n",
      "1086/1086 [==============================] - 0s 42us/step - loss: 0.4874 - categorical_accuracy: 0.7958 - val_loss: 0.5059 - val_categorical_accuracy: 0.7979\n",
      "Epoch 11/4000\n",
      "1086/1086 [==============================] - 0s 35us/step - loss: 0.4913 - categorical_accuracy: 0.8002 - val_loss: 0.4960 - val_categorical_accuracy: 0.8025\n",
      "Epoch 12/4000\n",
      "1086/1086 [==============================] - 0s 40us/step - loss: 0.4962 - categorical_accuracy: 0.8039 - val_loss: 0.4901 - val_categorical_accuracy: 0.8049\n",
      "Epoch 13/4000\n",
      "1086/1086 [==============================] - 0s 35us/step - loss: 0.4925 - categorical_accuracy: 0.8066 - val_loss: 0.4838 - val_categorical_accuracy: 0.8078\n",
      "Epoch 14/4000\n",
      "1086/1086 [==============================] - 0s 36us/step - loss: 0.4920 - categorical_accuracy: 0.8088 - val_loss: 0.4722 - val_categorical_accuracy: 0.8096\n",
      "Epoch 15/4000\n",
      "1086/1086 [==============================] - 0s 35us/step - loss: 0.4893 - categorical_accuracy: 0.8111 - val_loss: 0.4743 - val_categorical_accuracy: 0.8124\n",
      "Epoch 16/4000\n",
      "1086/1086 [==============================] - 0s 42us/step - loss: 0.4843 - categorical_accuracy: 0.8135 - val_loss: 0.4723 - val_categorical_accuracy: 0.8148\n",
      "Epoch 17/4000\n",
      "1086/1086 [==============================] - 0s 38us/step - loss: 0.4927 - categorical_accuracy: 0.8154 - val_loss: 0.4684 - val_categorical_accuracy: 0.8160\n",
      "Epoch 18/4000\n",
      "1086/1086 [==============================] - 0s 38us/step - loss: 0.4895 - categorical_accuracy: 0.8167 - val_loss: 0.4612 - val_categorical_accuracy: 0.8174\n",
      "Epoch 19/4000\n",
      "1086/1086 [==============================] - 0s 38us/step - loss: 0.4851 - categorical_accuracy: 0.8180 - val_loss: 0.4616 - val_categorical_accuracy: 0.8190\n",
      "Epoch 20/4000\n",
      "1086/1086 [==============================] - 0s 39us/step - loss: 0.4846 - categorical_accuracy: 0.8197 - val_loss: 0.4557 - val_categorical_accuracy: 0.8202\n",
      "Epoch 21/4000\n",
      "1086/1086 [==============================] - 0s 38us/step - loss: 0.4773 - categorical_accuracy: 0.8209 - val_loss: 0.4577 - val_categorical_accuracy: 0.8218\n",
      "Epoch 22/4000\n",
      "1086/1086 [==============================] - 0s 38us/step - loss: 0.4791 - categorical_accuracy: 0.8225 - val_loss: 0.4560 - val_categorical_accuracy: 0.8233\n",
      "Epoch 23/4000\n",
      "1086/1086 [==============================] - 0s 40us/step - loss: 0.4899 - categorical_accuracy: 0.8238 - val_loss: 0.4505 - val_categorical_accuracy: 0.8242\n",
      "Epoch 24/4000\n",
      "1086/1086 [==============================] - 0s 39us/step - loss: 0.4776 - categorical_accuracy: 0.8248 - val_loss: 0.4556 - val_categorical_accuracy: 0.8254\n",
      "Epoch 25/4000\n",
      "1086/1086 [==============================] - 0s 39us/step - loss: 0.4846 - categorical_accuracy: 0.8261 - val_loss: 0.4525 - val_categorical_accuracy: 0.8266\n",
      "Epoch 26/4000\n",
      "1086/1086 [==============================] - 0s 40us/step - loss: 0.4870 - categorical_accuracy: 0.8267 - val_loss: 0.4513 - val_categorical_accuracy: 0.8272\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input_list, y_train, epochs = 4000, batch_size = 50, callbacks=my_callbacks, validation_data=[test_input_list, y_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('Glass_Quality_Participants_Data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = testData.drop(columns=['pixel_area', 'xmax','ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = testfeatures.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = testfeatures.loc[:,['max_luminosity','thickness','xmin','ymin','log_area']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tfeatures)\n",
    "tfeatures = scaler.transform(tfeatures)\n",
    "\n",
    "tfeatures = pd.DataFrame(tfeatures,columns=['max_luminosity','thickness','xmin','ymin','log_area'])\n",
    "\n",
    "testfeatures = testfeatures.drop(columns=['max_luminosity','thickness','xmin','ymin','log_area'])\n",
    "\n",
    "normalized_features = pd.concat([testfeatures,tfeatures],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = normalized_features.copy()\n",
    "cat_features = f.loc[:,['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5']]\n",
    "\n",
    "\n",
    "cat_features['newf'] = cat_features.apply(lambda x: str(int(x[0]))+str(int(x[1]))+str(int(x[2]))+str(int(x[3]))+str(int(x[4]))+str(int(x[5]))+str(int(x[6])), axis=1)\n",
    "\n",
    "cat_features = cat_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "\n",
    "cat_features = cat_features.astype('string')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "cat_features['newf'] = pd.DataFrame(labelencoder.fit_transform(cat_features.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = normalized_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "norm_cat_features = pd.concat([normalized_features,cat_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_list = []\n",
    "\n",
    "val_input_list.append(norm_cat_features['newf'].values)\n",
    "val_input_list.append(norm_cat_features[othercols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds = model.predict(val_input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds_df = pd.DataFrame(testpreds, columns=['1','2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testpreds_df.to_excel('submission15.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
