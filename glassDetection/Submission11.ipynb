{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('Glass_Quality_Participants_Data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of columns = 16  Train\n",
    "# Number of rows = 1358   Train\n",
    "\n",
    "# Number of columns = 15  Test\n",
    "# Number of rows = 583   Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns\n",
    "# Index(['grade_A_Component_1', 'grade_A_Component_2', 'max_luminosity',\n",
    "#        'thickness', 'xmin', 'xmax', 'ymin', 'ymax', 'pixel_area', 'log_area',\n",
    "#        'x_component_1', 'x_component_2', 'x_component_3', 'x_component_4',\n",
    "#        'x_component_5', 'class'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trainData.iloc[:,:-1]\n",
    "labels = trainData.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.values.reshape(-1,1)\n",
    "# labels = np.array([i[0]-1 for i in labels]).reshape(-1,1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohencoder(labels):\n",
    "    return np.array([[0.1,0.9] if i[0] == 2 else [0.9,0.1] for i in labels])\n",
    "\n",
    "ohencoded_labels = ohencoder(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohencoded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and grade_A are categorical variables\n",
    "# No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features.hist(column=[\"xmax\", \"xmin\",\"ymin\",\"ymax\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.hist(column=[\"max_luminosity\",\"pixel_area\",\"log_area\"])#,,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_area and log_area\n",
    "# xmin and xmax\n",
    "# ymin and ymax\n",
    "# The above pairs have a very high degree of positive correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['pixel_area', 'xmax','ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = features.loc[:,['max_luminosity','thickness','xmin','ymin','log_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(tfeatures)\n",
    "tfeatures = scaler.transform(tfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = pd.DataFrame(tfeatures,columns=['max_luminosity','thickness','xmin','ymin','log_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['max_luminosity','thickness','xmin','ymin','log_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = pd.concat([features,tfeatures],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = normalized_features.copy()\n",
    "cat_features = f.loc[:,['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5']]\n",
    "\n",
    "\n",
    "cat_features['newf'] = cat_features.apply(lambda x: str(int(x[0]))+str(int(x[1]))+str(int(x[2]))+str(int(x[3]))+str(int(x[4]))+str(int(x[5]))+str(int(x[6])), axis=1)\n",
    "\n",
    "cat_features = cat_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "\n",
    "cat_features = cat_features.astype('string')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "cat_features['newf'] = pd.DataFrame(labelencoder.fit_transform(cat_features.iloc[:,0]))\n",
    "\n",
    "from numpy import unique\n",
    "n_labels = len(unique(cat_features['newf']))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = normalized_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features = pd.concat([normalized_features,cat_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_newf = np.unique(norm_cat_features['newf'])\n",
    "unique_newf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "inputs = []\n",
    "embeddings = []\n",
    "newf_cat = Input(shape=(1,))\n",
    "\n",
    "embedding = Embedding(11, 100, input_length=1)(newf_cat)\n",
    "embedding = Reshape(target_shape=(100,))(embedding)\n",
    "inputs.append(newf_cat)\n",
    "embeddings.append(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_luminosity', 'thickness', 'xmin', 'ymin', 'log_area']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "othercols = [c for c in norm_cat_features.columns if not(c == 'newf')]\n",
    "othercols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_numeric = Input(shape=(5,))\n",
    "embedding_numeric = Dense(16)(input_numeric) \n",
    "inputs.append(input_numeric)\n",
    "embeddings.append(embedding_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Concatenate()(embeddings)\n",
    "x = Dense(15, activation='relu')(x)\n",
    "x = Dropout(.5)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(.35)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "# x = Dropout(.15)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics =[tf.keras.metrics.CategoricalAccuracy()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    EarlyStopping(patience=3),\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features = norm_cat_features\n",
    "np_labels = ohencoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np_features, np_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1086, 6), (272, 6))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_list = []\n",
    "test_input_list = []\n",
    "\n",
    "train_input_list.append(X_train['newf'].values)\n",
    "train_input_list.append(X_train[othercols].values)\n",
    "\n",
    "test_input_list.append(X_test['newf'].values)\n",
    "test_input_list.append(X_test[othercols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1086 samples, validate on 272 samples\n",
      "Epoch 1/4000\n",
      "1086/1086 [==============================] - 0s 25us/step - loss: 0.4780 - categorical_accuracy: 0.8440 - val_loss: 0.4471 - val_categorical_accuracy: 0.8440\n",
      "Epoch 2/4000\n",
      "1086/1086 [==============================] - 0s 24us/step - loss: 0.4788 - categorical_accuracy: 0.8440 - val_loss: 0.4484 - val_categorical_accuracy: 0.8440\n",
      "Epoch 3/4000\n",
      "1086/1086 [==============================] - 0s 26us/step - loss: 0.4860 - categorical_accuracy: 0.8440 - val_loss: 0.4482 - val_categorical_accuracy: 0.8441\n",
      "Epoch 4/4000\n",
      "1086/1086 [==============================] - 0s 23us/step - loss: 0.4836 - categorical_accuracy: 0.8440 - val_loss: 0.4460 - val_categorical_accuracy: 0.8441\n",
      "Epoch 5/4000\n",
      "1086/1086 [==============================] - 0s 23us/step - loss: 0.4798 - categorical_accuracy: 0.8441 - val_loss: 0.4471 - val_categorical_accuracy: 0.8441\n",
      "Epoch 6/4000\n",
      "1086/1086 [==============================] - 0s 25us/step - loss: 0.4764 - categorical_accuracy: 0.8441 - val_loss: 0.4489 - val_categorical_accuracy: 0.8441\n",
      "Epoch 7/4000\n",
      "1086/1086 [==============================] - 0s 23us/step - loss: 0.4828 - categorical_accuracy: 0.8441 - val_loss: 0.4472 - val_categorical_accuracy: 0.8441\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input_list, y_train, epochs = 4000, batch_size = 50, callbacks=my_callbacks, validation_data=[test_input_list, y_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('Glass_Quality_Participants_Data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = testData.drop(columns=['pixel_area', 'xmax','ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = testfeatures.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = testfeatures.loc[:,['max_luminosity','thickness','xmin','ymin','log_area']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tfeatures)\n",
    "tfeatures = scaler.transform(tfeatures)\n",
    "\n",
    "tfeatures = pd.DataFrame(tfeatures,columns=['max_luminosity','thickness','xmin','ymin','log_area'])\n",
    "\n",
    "testfeatures = testfeatures.drop(columns=['max_luminosity','thickness','xmin','ymin','log_area'])\n",
    "\n",
    "normalized_features = pd.concat([testfeatures,tfeatures],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = normalized_features.copy()\n",
    "cat_features = f.loc[:,['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5']]\n",
    "\n",
    "\n",
    "cat_features['newf'] = cat_features.apply(lambda x: str(int(x[0]))+str(int(x[1]))+str(int(x[2]))+str(int(x[3]))+str(int(x[4]))+str(int(x[5]))+str(int(x[6])), axis=1)\n",
    "\n",
    "cat_features = cat_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "\n",
    "cat_features = cat_features.astype('string')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "cat_features['newf'] = pd.DataFrame(labelencoder.fit_transform(cat_features.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = normalized_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "norm_cat_features = pd.concat([normalized_features,cat_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_luminosity</th>\n",
       "      <th>thickness</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>log_area</th>\n",
       "      <th>newf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.679864</td>\n",
       "      <td>-0.239898</td>\n",
       "      <td>-1.073367</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>-0.235592</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.061834</td>\n",
       "      <td>0.380407</td>\n",
       "      <td>-0.895470</td>\n",
       "      <td>-0.814742</td>\n",
       "      <td>-0.264147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.829152</td>\n",
       "      <td>-0.787227</td>\n",
       "      <td>-1.013423</td>\n",
       "      <td>6.431615</td>\n",
       "      <td>-0.284460</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.331524</td>\n",
       "      <td>-0.714249</td>\n",
       "      <td>-1.026959</td>\n",
       "      <td>-0.746927</td>\n",
       "      <td>0.128006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265629</td>\n",
       "      <td>-0.057455</td>\n",
       "      <td>-1.092703</td>\n",
       "      <td>2.117568</td>\n",
       "      <td>-0.204373</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.813020</td>\n",
       "      <td>-0.422341</td>\n",
       "      <td>1.722705</td>\n",
       "      <td>-0.214630</td>\n",
       "      <td>-0.294414</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0.514443</td>\n",
       "      <td>-0.641272</td>\n",
       "      <td>-0.938010</td>\n",
       "      <td>-0.833021</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.215866</td>\n",
       "      <td>-0.623028</td>\n",
       "      <td>-1.135244</td>\n",
       "      <td>-0.633502</td>\n",
       "      <td>2.554299</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>3.749025</td>\n",
       "      <td>1.310866</td>\n",
       "      <td>-0.336642</td>\n",
       "      <td>-0.844290</td>\n",
       "      <td>0.922651</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.912546</td>\n",
       "      <td>-0.604784</td>\n",
       "      <td>1.216086</td>\n",
       "      <td>-0.121691</td>\n",
       "      <td>-0.318380</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_luminosity  thickness      xmin      ymin  log_area  newf\n",
       "0         -0.679864  -0.239898 -1.073367  0.010044 -0.235592     9\n",
       "1          1.061834   0.380407 -0.895470 -0.814742 -0.264147     0\n",
       "2         -0.829152  -0.787227 -1.013423  6.431615 -0.284460     5\n",
       "3         -0.331524  -0.714249 -1.026959 -0.746927  0.128006     3\n",
       "4          0.265629  -0.057455 -1.092703  2.117568 -0.204373     6\n",
       "..              ...        ...       ...       ...       ...   ...\n",
       "578        0.813020  -0.422341  1.722705 -0.214630 -0.294414     6\n",
       "579        0.514443  -0.641272 -0.938010 -0.833021  0.045471     3\n",
       "580        0.215866  -0.623028 -1.135244 -0.633502  2.554299     3\n",
       "581        3.749025   1.310866 -0.336642 -0.844290  0.922651     5\n",
       "582        0.912546  -0.604784  1.216086 -0.121691 -0.318380     2\n",
       "\n",
       "[583 rows x 6 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_list = []\n",
    "\n",
    "val_input_list.append(norm_cat_features['newf'].values)\n",
    "val_input_list.append(norm_cat_features[othercols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds = model.predict(val_input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds_df = pd.DataFrame(testpreds, columns=['1','2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds_df.to_excel('submission10.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
