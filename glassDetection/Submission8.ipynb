{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('Glass_Quality_Participants_Data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of columns = 16  Train\n",
    "# Number of rows = 1358   Train\n",
    "\n",
    "# Number of columns = 15  Test\n",
    "# Number of rows = 583   Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns\n",
    "# Index(['grade_A_Component_1', 'grade_A_Component_2', 'max_luminosity',\n",
    "#        'thickness', 'xmin', 'xmax', 'ymin', 'ymax', 'pixel_area', 'log_area',\n",
    "#        'x_component_1', 'x_component_2', 'x_component_3', 'x_component_4',\n",
    "#        'x_component_5', 'class'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trainData.iloc[:,:-1]\n",
    "labels = trainData.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.values.reshape(-1,1)\n",
    "# labels = np.array([i[0]-1 for i in labels]).reshape(-1,1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohencoder(labels):\n",
    "    return np.array([[0,1] if i[0] == 2 else [1,0] for i in labels])\n",
    "\n",
    "ohencoded_labels = ohencoder(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohencoded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and grade_A are categorical variables\n",
    "# No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features.hist(column=[\"xmax\", \"xmin\",\"ymin\",\"ymax\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.hist(column=[\"max_luminosity\",\"pixel_area\",\"log_area\"])#,,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_area and log_area\n",
    "# xmin and xmax\n",
    "# ymin and ymax\n",
    "# The above pairs have a very high degree of positive correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['pixel_area', 'xmax','ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = features.loc[:,['max_luminosity','thickness','xmin','ymin','log_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(tfeatures)\n",
    "tfeatures = scaler.transform(tfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = pd.DataFrame(tfeatures,columns=['max_luminosity','thickness','xmin','ymin','log_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['max_luminosity','thickness','xmin','ymin','log_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = pd.concat([features,tfeatures],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = normalized_features.copy()\n",
    "cat_features = f.loc[:,['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5']]\n",
    "\n",
    "\n",
    "cat_features['newf'] = cat_features.apply(lambda x: str(int(x[0]))+str(int(x[1]))+str(int(x[2]))+str(int(x[3]))+str(int(x[4]))+str(int(x[5]))+str(int(x[6])), axis=1)\n",
    "\n",
    "cat_features = cat_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "\n",
    "cat_features = cat_features.astype('string')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "cat_features['newf'] = pd.DataFrame(labelencoder.fit_transform(cat_features.iloc[:,0]))\n",
    "\n",
    "from numpy import unique\n",
    "n_labels = len(unique(cat_features['newf']))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = normalized_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features = pd.concat([normalized_features,cat_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_newf = np.unique(norm_cat_features['newf'])\n",
    "unique_newf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "inputs = []\n",
    "embeddings = []\n",
    "newf_cat = Input(shape=(1,))\n",
    "\n",
    "embedding = Embedding(11, 6, input_length=1)(newf_cat)\n",
    "embedding = Reshape(target_shape=(6,))(embedding)\n",
    "inputs.append(newf_cat)\n",
    "embeddings.append(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_luminosity', 'thickness', 'xmin', 'ymin', 'log_area']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "othercols = [c for c in norm_cat_features.columns if not(c == 'newf')]\n",
    "othercols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_numeric = Input(shape=(5,))\n",
    "embedding_numeric = Dense(16)(input_numeric) \n",
    "inputs.append(input_numeric)\n",
    "embeddings.append(embedding_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Concatenate()(embeddings)\n",
    "x = Dense(15, activation='relu')(x)\n",
    "x = Dropout(.5)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(.35)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "# x = Dropout(.15)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics =[tf.keras.metrics.CategoricalAccuracy()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    EarlyStopping(patience=3),\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features = norm_cat_features\n",
    "np_labels = ohencoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np_features, np_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_list = []\n",
    "test_input_list = []\n",
    "\n",
    "train_input_list.append(X_train['newf'].values)\n",
    "train_input_list.append(X_train[othercols].values)\n",
    "\n",
    "test_input_list.append(X_test['newf'].values)\n",
    "test_input_list.append(X_test[othercols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1086 samples, validate on 272 samples\n",
      "Epoch 1/4000\n",
      "1086/1086 [==============================] - 0s 26us/step - loss: 0.3079 - categorical_accuracy: 0.8510 - val_loss: 0.2477 - val_categorical_accuracy: 0.8510\n",
      "Epoch 2/4000\n",
      "1086/1086 [==============================] - 0s 26us/step - loss: 0.2978 - categorical_accuracy: 0.8510 - val_loss: 0.2487 - val_categorical_accuracy: 0.8510\n",
      "Epoch 3/4000\n",
      "1086/1086 [==============================] - 0s 27us/step - loss: 0.3005 - categorical_accuracy: 0.8510 - val_loss: 0.2512 - val_categorical_accuracy: 0.8510\n",
      "Epoch 4/4000\n",
      "1086/1086 [==============================] - 0s 23us/step - loss: 0.3048 - categorical_accuracy: 0.8510 - val_loss: 0.2462 - val_categorical_accuracy: 0.8510\n",
      "Epoch 5/4000\n",
      "1086/1086 [==============================] - 0s 23us/step - loss: 0.3085 - categorical_accuracy: 0.8510 - val_loss: 0.2517 - val_categorical_accuracy: 0.8510\n",
      "Epoch 6/4000\n",
      "1086/1086 [==============================] - 0s 25us/step - loss: 0.2985 - categorical_accuracy: 0.8510 - val_loss: 0.2488 - val_categorical_accuracy: 0.8510\n",
      "Epoch 7/4000\n",
      "1086/1086 [==============================] - 0s 26us/step - loss: 0.3059 - categorical_accuracy: 0.8510 - val_loss: 0.2439 - val_categorical_accuracy: 0.8511\n",
      "Epoch 8/4000\n",
      "1086/1086 [==============================] - 0s 26us/step - loss: 0.2993 - categorical_accuracy: 0.8511 - val_loss: 0.2414 - val_categorical_accuracy: 0.8511\n",
      "Epoch 9/4000\n",
      "1086/1086 [==============================] - 0s 23us/step - loss: 0.3071 - categorical_accuracy: 0.8511 - val_loss: 0.2465 - val_categorical_accuracy: 0.8511\n",
      "Epoch 10/4000\n",
      "1086/1086 [==============================] - 0s 19us/step - loss: 0.3092 - categorical_accuracy: 0.8511 - val_loss: 0.2490 - val_categorical_accuracy: 0.8511\n",
      "Epoch 11/4000\n",
      "1086/1086 [==============================] - 0s 23us/step - loss: 0.3044 - categorical_accuracy: 0.8511 - val_loss: 0.2470 - val_categorical_accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input_list, y_train, epochs = 4000, batch_size = 50, callbacks=my_callbacks, validation_data=[test_input_list, y_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('Glass_Quality_Participants_Data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = testData.drop(columns=['pixel_area', 'xmax','ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = testfeatures.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeatures = testfeatures.loc[:,['max_luminosity','thickness','xmin','ymin','log_area']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tfeatures)\n",
    "tfeatures = scaler.transform(tfeatures)\n",
    "\n",
    "tfeatures = pd.DataFrame(tfeatures,columns=['max_luminosity','thickness','xmin','ymin','log_area'])\n",
    "\n",
    "testfeatures = testfeatures.drop(columns=['max_luminosity','thickness','xmin','ymin','log_area'])\n",
    "\n",
    "normalized_features = pd.concat([testfeatures,tfeatures],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = normalized_features.copy()\n",
    "cat_features = f.loc[:,['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5']]\n",
    "\n",
    "\n",
    "cat_features['newf'] = cat_features.apply(lambda x: str(int(x[0]))+str(int(x[1]))+str(int(x[2]))+str(int(x[3]))+str(int(x[4]))+str(int(x[5]))+str(int(x[6])), axis=1)\n",
    "\n",
    "cat_features = cat_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "\n",
    "cat_features = cat_features.astype('string')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "cat_features['newf'] = pd.DataFrame(labelencoder.fit_transform(cat_features.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = normalized_features.drop(columns = ['grade_A_Component_1','grade_A_Component_2','x_component_1','x_component_2','x_component_3','x_component_4','x_component_5'])\n",
    "norm_cat_features = pd.concat([normalized_features,cat_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_list = []\n",
    "\n",
    "val_input_list.append(norm_cat_features['newf'].values)\n",
    "val_input_list.append(norm_cat_features[othercols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds = model.predict(val_input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds_df = pd.DataFrame(testpreds, columns=['1','2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds_df.to_excel('submission8.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
